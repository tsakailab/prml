{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/prml/blob/master/ipynb/ex_MNIST_knn_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UTNIg2oEn2n8"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST手書き数字画像のk近傍識別（k-NN）\n",
        "$k$-nearest neighbors classification ($k$-NN) of the MNIST digits\n",
        "\n",
        "----\n",
        "\n",
        "氏名：\n",
        "\n",
        "学生番号：\n",
        "\n",
        "----\n",
        "## 基本課題（必須）\n",
        "\n",
        "    1. 訓練データ数が100のときのk-NNの正答率（accuracy）と，\n",
        "       起こりやすい誤識別を報告してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    2. 訓練データ数が小さいとき，どのような正答率の改善策が考えられますか．\n",
        "       実際に改善の効果はどうでしたか．その理由も考察してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    3. 訓練データ数を増やす利点と欠点をそれぞれ定量的に述べてください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    4.その他，気づいたこと，調べたことを書いてください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "発展課題（任意）がこのノートブックの後半にあります．"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データ集合を取得します．"
      ],
      "metadata": {
        "id": "GKxBfkhj8QZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "# [MNIST](http://yann.lecun.com/exdb/mnist/)\n",
        "tvds = datasets.MNIST('./data', download=True, train=True)\n",
        "\n",
        "# [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
        "#tvds = datasets.FashionMNIST('./data', download=True, train=True)\n",
        "\n",
        "# [Kuzushiji-MNIST](https://github.com/rois-codh/kmnist)\n",
        "#tvds = datasets.KMNIST('./data', download=True, train=True)\n",
        "\n",
        "Ximages_all, y_all = tvds.data.numpy(), tvds.targets.numpy()\n",
        "\n",
        "# [EMNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.EMNIST.html)\n",
        "#tvds = datasets.EMNIST('./data', download=True, train=True, split='letters')\n",
        "#Ximages_all, y_all = tvds.data.transpose_(-1,-2).numpy(), tvds.targets.numpy() - 1\n"
      ],
      "metadata": {
        "id": "iFGaBeiY7wNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ☆画像数とサイズを確認します（画像を加工したい場合はこのセルを編集して利用してください）．\n",
        "import numpy as np\n",
        "from skimage.filters import gaussian\n",
        "from skimage.exposure import equalize_hist as eh\n",
        "from skimage.transform import resize\n",
        "\n",
        "Ximages = Ximages_all.copy()\n",
        "y = y_all.copy()\n",
        "\n",
        "'''\n",
        "* blurring (https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.gaussian)\n",
        "* histogram equalization (https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_equalize.html)\n",
        "* resize images (https://scikit-image.org/docs/stable/auto_examples/transform/plot_rescale.html)\n",
        "'''\n",
        "#Ximages = gaussian(np.float32(Ximages_all.transpose((1,2,0))), sigma=1.0, channel_axis=-1).transpose(2,0,1)\n",
        "#Ximages = eh(Ximages_all.transpose((1,2,0))).transpose(2,0,1) * 255\n",
        "#height, width = 8, 8; Ximages = resize(np.float32(Ximages_all.transpose((1,2,0))), (height, width)).transpose(2,0,1)\n",
        "\n",
        "''' simulate noisy images '''\n",
        "#Ximages = Ximages + np.random.rand(*Ximages.shape) * 200; Ximages = np.clip(Ximages,a_min=0,a_max=255)\n",
        "\n",
        "Ximages = np.uint8(Ximages)\n",
        "print(\"(#images, height, width)\", Ximages.shape)\n",
        "print(Ximages.dtype, \", max. pixel value = \", Ximages.max())"
      ],
      "metadata": {
        "id": "L_22PEa08NBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST class labels\n",
        "\n",
        "| [MNIST](http://yann.lecun.com/exdb/mnist/) | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |\n",
        "| - | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
        "| [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) | **T-shirt/top** | Trouser | **Pullover** | Dress | **Coat** | Sandal |  **Shirt** | Sneaker | Bag | Ankle boot |\n",
        "| [Kuzushiji-MNIST](https://github.com/rois-codh/kmnist) | お | き | す | つ | な | は |  ま | や | れ | を |"
      ],
      "metadata": {
        "id": "VFE1WbHu8U-U"
      }
    },
    {
      "metadata": {
        "id": "E7Ib1PU2n2oK",
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title 画像を表示する関数 implot を定義し，画像を例示します．\n",
        "%matplotlib inline\n",
        "!wget -q -N https://gist.githubusercontent.com/tsakai-g/c54a8fa059f9c655290586ec1cc2ec7b/raw/implot.py\n",
        "%run implot.py\n",
        "\n",
        "print(\"%d images in total\" % len(y))\n",
        "p = np.random.permutation(len(y))\n",
        "implot(Ximages[p], y[p], num=16, vmin=0, vmax=255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQFrBwjAn2oS"
      },
      "cell_type": "markdown",
      "source": [
        "### 実行と評価\n",
        "\n",
        "#### 設定値\n",
        "- `train_size`: 訓練データ（プロトタイプ）の数\n",
        "- `k`: 識別の参考にする近傍の訓練データ数"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "\n",
        "train_size = 1000\n",
        "k = 1   # try k = 1, 3, 7, 15, 31, ...\n",
        "\n",
        "clf = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
        "#clf = neighbors.KNeighborsClassifier(n_neighbors = k, metric='cosine')\n",
        "\n",
        "val_size = 1000"
      ],
      "metadata": {
        "id": "arAOq-4QlcA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 識別の実行と結果の例示\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "# split the data into training and validation sets\n",
        "Ximages_train, Ximages_val, y_train, y_val = train_test_split(Ximages, y,\n",
        "                                                              train_size=train_size, test_size=val_size)\n",
        "\n",
        "# NumPy array of shape (#data, #pixels) for k-NN\n",
        "X_train = np.reshape(Ximages_train, (Ximages_train.shape[0], -1))\n",
        "X_val = np.reshape(Ximages_val, (Ximages_val.shape[0], -1))\n",
        "\n",
        "# let clf prepare the inference\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# predict the labels of the test data\n",
        "y_pred = clf.predict(X_val)\n",
        "\n",
        "# show examples of the prediction\n",
        "p = np.random.permutation(len(y_val))\n",
        "implot(Ximages_val[p], y_val[p], y_pred[p], num=16, vmin=0, vmax=255)\n",
        "\n",
        "# the number of correct matches / the total number of data points\n",
        "matches = (y_pred == y_val)\n",
        "print(\"Accuracy = %d / %d = %2.1f%%\" % (matches.sum(), len(matches), 100*matches.sum()/float(len(matches))))"
      ],
      "metadata": {
        "id": "K9nCZ5D6groz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EgIqtl7Yn2oU",
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title 反復試行による性能評価（時間がかかります）\n",
        "\n",
        "ntry = 100\n",
        "accuracy = np.zeros(ntry)\n",
        "for i in range(ntry):\n",
        "    # split the data into training and validation sets\n",
        "    Ximages_train, Ximages_val, y_train, y_val = train_test_split(Ximages, y,\n",
        "                                                                  train_size=train_size, test_size=val_size)\n",
        "\n",
        "    # NumPy array of shape (#data, #pixels) for k-NN\n",
        "    X_train = np.reshape(Ximages_train, (Ximages_train.shape[0], -1))\n",
        "    X_val = np.reshape(Ximages_val, (Ximages_val.shape[0], -1))\n",
        "\n",
        "    # let clf prepare the inference\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # predict the labels of the test data\n",
        "    y_pred = clf.predict(X_val)\n",
        "\n",
        "    # the number of correct matches / the total number of data points\n",
        "    accuracy[i] = (y_pred == y_val).sum() / len(y_pred)\n",
        "\n",
        "print(u\"Accuracy = %2.1f\\u00B1%2.1f%% [%2.1f%%, %2.1f%%]\"\n",
        "      % (accuracy.mean()*100, accuracy.std()*100, accuracy.min()*100, accuracy.max()*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRUeztQpn2op",
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title 混同行列（行：正解，列：予測）\n",
        "from sklearn import metrics\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "\n",
        "cm = metrics.confusion_matrix(y_val, y_pred)\n",
        "print(cm)\n",
        "\n",
        "#print(cm.sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------"
      ],
      "metadata": {
        "id": "h4Xq7nKCMeqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 発展課題\n",
        "\n",
        "k-NN をクラスで自作しましょう．[sklearn.neighbors.KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) に似た仕様とします．\n",
        "\n",
        "例えば，訓練データ `X_train` とクラスラベル `y_train` から最近傍法で `X_val` のクラスラベルの予測 `y_pred` を得るには\n",
        "```\n",
        "    k = 1\n",
        "    myclf = kNN(k)\n",
        "    myclf.fit(X_train, y_train)\n",
        "    y_pred = myclf.predict(X_val)\n",
        "```\n",
        "のように使うことを想定します．\n",
        "MNISTで訓練データが1000個の場合，`X_train` と `y_train` はそれぞれ shape が (1000,784) と (1000,) のNumPy配列です．"
      ],
      "metadata": {
        "id": "qFMWVuCjsNG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "# https://docs.python.org/3/library/collections.html#collections.Counter\n",
        "\n",
        "# x1 と x2 の間の距離を返す関数\n",
        "def distance(x1, x2):\n",
        "    return np.sqrt(np.sum((np.float32(x1) - np.float32(x2))**2))\n",
        "\n",
        "# 自作の k-NN をクラスで定義しましょう．\n",
        "class kNN:\n",
        "\n",
        "    # 初期化の関数です．\n",
        "    # myclf = kNN(k) のように引数で与えられた k を self.k に記憶しておきます．\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    # myclf.fit(X, y) のように訓練データ X と 正解ラベル y が与えられます．\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    # myclf.predict(X) とすると，Xの各行のデータを識別した結果を返します．\n",
        "    def predict(self, X):\n",
        "        y_pred = [self._predict(x) for x in X]\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        # compute distances between x and all training data\n",
        "        # hint: distance(), self.X_train\n",
        "        distances = ######## your code here ########\n",
        "\n",
        "        # sort by distance and return indices of the first k neighbors\n",
        "        # hint: np.argsort(), distances, self.k\n",
        "        k_idx = ######## your code here ########\n",
        "\n",
        "        # extract the labels of the k nearest neighbor training samples\n",
        "        # hint: self.y_train, k_index\n",
        "        k_neighbor_labels = ######## your code here ########\n",
        "\n",
        "        # return the most common class label\n",
        "        pred = Counter(k_neighbor_labels).most_common(1)[0][0]\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "ySO1HTYEwqOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 自作の k-NN 識別器 myclf を生成する．\n",
        "# instanciate my own kNN classifier\n",
        "myclf = kNN(k)\n",
        "\n",
        "# 以下，変更は不要です．\n",
        "# no need to modify the following lines\n",
        "\n",
        "# split the data into training and validation sets\n",
        "Ximages_train, Ximages_val, y_train, y_val = train_test_split(Ximages, y,\n",
        "                                                              train_size=train_size, test_size=val_size)\n",
        "\n",
        "# NumPy array of shape (#data, #pixels) for k-NN\n",
        "X_train = np.reshape(Ximages_train, (Ximages_train.shape[0], -1))\n",
        "X_val = np.reshape(Ximages_val, (Ximages_val.shape[0], -1))\n",
        "\n",
        "# let clf prepare the inference\n",
        "myclf.fit(X_train, y_train)\n",
        "\n",
        "# predict the labels of the test data\n",
        "y_pred = myclf.predict(X_val)\n",
        "\n",
        "# show examples of the prediction\n",
        "p = np.random.permutation(len(y_val))\n",
        "implot(Ximages_val[p], y_val[p], y_pred[p], num=16, vmin=0, vmax=255)\n",
        "\n",
        "# the number of correct matches / the total number of data points\n",
        "matches = (y_pred == y_val)\n",
        "print(\"Accuracy = %d / %d = %2.1f%%\" % (matches.sum(), len(matches), 100*matches.sum()/float(len(matches))))"
      ],
      "metadata": {
        "id": "64N_WITlw8yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "お疲れさまでした．"
      ],
      "metadata": {
        "id": "-svKKyHE-Vcl"
      }
    }
  ]
}