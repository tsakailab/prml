{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/prml/blob/master/ipynb/ex_Perceptrons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# パーセプトロンの動作について学ぶ（Behavior of perceptrons）\n",
        "----\n",
        "\n",
        "氏名：\n",
        "\n",
        "学生番号：\n",
        "\n",
        "----\n",
        "[A Neural Network Playground](http://playground.tensorflow.org/)を用いて，パーセプトロンの振る舞い考察しましょう．\n",
        "Playground詳しい説明は[ここにあります](https://cloud.google.com/blog/products/ai-machine-learning/understanding-neural-networks-with-tensorflow-playground)．\n",
        "\n",
        "以下の課題に取り組む際の注意点です．\n",
        "- \"Run/Pause\"の左のボタン\"Reset the network\"を用いて反復試行すること．必ず同じモデルに収束するとは限りません．\n",
        "- 左下の\"[REGENERATE]\"で再生成したデータも試すこと．特定のデータについてではなく，普遍的に言える事柄を見つけましょう．\n",
        "- 十分収束するまで観察すること．学習中のモデルよりも必ず良いモデルに収束するのでしょうか．\n",
        "- 右下の\"Show test data\"で表示されるデータ（訓練データ以外のデータ）に対しても識別できているかどうかで評価すること．\n",
        "\n",
        "特に，訓練データが少なく，ノイズの影響も無視できない問題設定にすると，考察に有益です．  \n",
        "Ratio of training to test data: 20%，Noise: 25 の設定で実験します．\n",
        "\n",
        "(a) [モデル：単純パーセプトロン，　データセット：\"Gaussian\"](https://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0.01&noise=30&networkShape=&seed=0.85984&showTestData=false&discretize=true&percTrainData=20&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&batchSize_hide=false)\n",
        "\n",
        "(b) [モデル：3層パーセプトロン，　データセット：\"Circle\"](https://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.3&regularizationRate=0.01&noise=25&networkShape=1&seed=0.28240&showTestData=false&discretize=true&percTrainData=20&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&batchSize_hide=false)\n",
        "\n",
        "(c) [モデル：単純パーセプトロン，データセット：\"Circle\"](https://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.3&regularizationRate=0.01&noise=25&networkShape=&seed=0.64557&showTestData=false&discretize=true&percTrainData=20&x=true&y=true&xTimesY=true&xSquared=true&ySquared=true&cosX=false&sinX=true&cosY=false&sinY=true&collectStats=false&problem=classification&initZero=false&hideText=false&batchSize_hide=false)\n",
        "\n",
        "まず，(a)で，単純パーセプトロンが線形識別器であることを確認してから，課題に着手しましょう．"
      ],
      "metadata": {
        "id": "b_Ll73T9wjPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## 基本課題（必須）\n",
        "\n",
        "    1. (b)では，中間層に何個以上のノード（neurons）が必要ですか．その理由を述べてください（結果論は不可です）．\n",
        "      また，多数のノード（例えば8個）で学習を続けると，どのような問題が生じますか．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    2. (c)のモデルは単純パーセプトロンなのに，決定境界が直線でないのはなぜですか．\n",
        "      また，入力しているどの特徴が強く使われる傾向がありますか．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    3. 正則化（regularization）を\"L1\"に設定すると，モデルに特徴を選択させる学習の効果があります．この効果を(c)の例で具体的に説明してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    4.その他，気づいたこと，調べたことがあれば書いてください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-KmrX-7HqF9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### ヒント\n",
        "\n",
        "- 3層パーセプトロンの設定で，Activation（活性化関数）を ReLU にしてみましょう．ReLU(x)=max(x, 0)は x が負のときだけ 0 にする関数です．\n",
        "- [この例](https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=3&seed=0.27615&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)のように，多角形の領域が作られることがあります．その理由を考えましょう．\n",
        "- この3層パーセプトロンは，2入力1出力の関数です．[そのグラフと等高線を描けます](https://www.wolframalpha.com/input?i=plot%28+%28+-1.2*max%281.2x%2B0.35y-0.33%2C+0%29+-+1.3*max%28-0.22x-1.2y-0.61%2C+0%29+-+1.3*max%28-0.93x%2B0.81y-0.58%2C0%29++%29+for+x+from+-6+to+6+for+y+from+-6+to+6%29)　[[出典]](https://datascience.stackexchange.com/questions/76022/what-does-the-descision-boundary-of-a-relu-look-like)．"
      ],
      "metadata": {
        "id": "26qaoe5RsvVI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW1hl94VG9Z8"
      },
      "source": [
        "----\n",
        "## 発展課題（任意）\n",
        "\n",
        "Playgroundの右上に表示される \"Test loss\"，\"Training loss\" について考えましょう．\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2次元に2クラスを描く `plot2cls` を定義します（理解不要）．\n",
        "!wget -q -N https://gist.githubusercontent.com/tsakai-g/1920bc185be0c497579968e00a9b3674/raw/plot2cls.py\n",
        "%run plot2cls.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VvmOmGO2jR-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPcFoZwoU2fp",
        "cellView": "form"
      },
      "source": [
        "#@title 例題用のデータを生成します．\n",
        "import numpy as np\n",
        "npos = 30\n",
        "nneg = 30\n",
        "np.random.seed(321)\n",
        "X = np.r_[np.random.randn(npos, 2) + [3, 3], np.random.randn(nneg, 2)]\n",
        "# [1,1,...,1,-1,-1,...,-1]\n",
        "y = np.array([1] * npos + [-1] * nneg)\n",
        "\n",
        "plot2cls(X, y).plot_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 損失関数を定義します．"
      ],
      "metadata": {
        "id": "bSLGHQlGrBb6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJxRr0_4G9aI"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def LogisticLoss(y, g):\n",
        "    return np.mean(np.log(1.0 + np.exp(-y*g)))\n",
        "\n",
        "def HingeLoss(y, g):\n",
        "    return np.mean(np.maximum(1.0 - y*g, 0.0))\n",
        "\n",
        "# 線形識別関数\n",
        "def g(X, w):\n",
        "    return w[0] + np.dot(X, w[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $[w_0, w_1, w_2]^\\top$はパーセプトロンの重みです．表示される損失関数の値がなるべく小さくなるように調整してください．\n",
        "    1. どのようなとき，損失が大きく・小さくなりますか．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "    2. w0, w1, w2 によって決定境界はどのように変わりますか．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7FUjbZ2jrXbX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIQAY-CgG9ah",
        "cellView": "form"
      },
      "source": [
        "from sklearn.linear_model import Hinge\n",
        "#@title {run: \"auto\"}\n",
        "w0 = -0.1 #@param{type:\"slider\", min:-5, max:5, step:0.1}\n",
        "w1 = -1 #@param{type:\"slider\", min:-5, max:5, step:0.1}\n",
        "w2 = 1.7 #@param{type:\"slider\", min:-5, max:5, step:0.1}\n",
        "w = np.array( [w0, w1, w2] )\n",
        "\n",
        "ll = LogisticLoss(y, g(X, w))\n",
        "hl = HingeLoss(y, g(X, w))\n",
        "print('\\n'*2, \"Logistic loss = %f,  Hinge loss =%f\" % (ll, hl), '\\n'*2)\n",
        "plotter = plot2cls(X, y, lambda X: g(X, w), levels={0.0:'-'}, dx=0.2)\n",
        "plotter.plot_clf()\n",
        "#plotter.plot_data()\n",
        "#plotter.plot_hist()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}