{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/prml/blob/master/ipynb/ex_MNIST_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST画像のロジスティック回帰（logistic regression on MNIST datasets）\n",
        "\n",
        "MNIST画像の識別問題において，ロジスティック回帰で学習した単純パーセプトロンの重みを可視化します．\n",
        "\n",
        "----\n",
        "\n",
        "氏名：\n",
        "\n",
        "学生番号：\n",
        "\n",
        "----\n",
        "## 基本課題（必須）\n",
        "\n",
        "    1. 「★ロジスティック回帰を実行します．」で，損失の係数`C`を小さい値に設定し，L2正則化の効果を強くすると，\n",
        "       訓練データ（training data）と検証データ（validation data）の正答率はどう変わりますか．\n",
        "       また，パーセプトロンの重みはどうなりますか．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    2. 「★学習した重みを可視化し，識別関数を計算します．」を実行すると，\n",
        "       (a)識別に役立つ特徴が学習によって見つけられていること，(b)識別的特徴に基づき識別関数が計算されていること  \n",
        "       を観察できます．表示される図や数値をどのように見ると(a)と(b)を確認できますか．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    3. 手書き数字画像以外のデータ集合（例えばFashion-MNIST）で2つのクラスを選択し，2クラス識別器を作成してください．\n",
        "       パーセプトロンの重みから，その2つのクラスにはどのような特徴の違いが見つかりましたか．\n",
        "       また，「★ロジスティック回帰を実行します．」において，どのような設定でLogisticRegression()を使用すると，\n",
        "       選択した2クラスの識別的特徴が考察しやすいですか．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    4.その他，気づいたこと，調べたことがあれば書いてください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "発展課題（任意）がこのノートブックの後半にあります．"
      ],
      "metadata": {
        "id": "AH8-0BiKPDuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データ集合を取得します．"
      ],
      "metadata": {
        "id": "tC7fn8ijeihu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "# [MNIST](http://yann.lecun.com/exdb/mnist/)\n",
        "tvds = datasets.MNIST('./data', download=True, train=True)\n",
        "\n",
        "# [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
        "#tvds = datasets.FashionMNIST('./data', download=True, train=True)\n",
        "\n",
        "# [Kuzushiji-MNIST](https://github.com/rois-codh/kmnist)\n",
        "#tvds = datasets.KMNIST('./data', download=True, train=True)\n",
        "\n",
        "Ximages_all, y_all = tvds.data.numpy(), tvds.targets.numpy()\n",
        "\n",
        "# [EMNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.EMNIST.html)\n",
        "#tvds = datasets.EMNIST('./data', download=True, train=True, split='letters')\n",
        "#Ximages_all, y_all = tvds.data.transpose_(-1,-2).numpy(), tvds.targets.numpy() - 1"
      ],
      "metadata": {
        "id": "pBKK4QZN1eCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ☆画像数とサイズを確認します（画像を加工したい場合はこのセルを編集して利用してください）．\n",
        "import numpy as np\n",
        "from skimage.filters import gaussian\n",
        "from skimage.exposure import equalize_hist as eh\n",
        "from skimage.transform import resize\n",
        "\n",
        "Ximages = Ximages_all.copy()\n",
        "y = y_all.copy()\n",
        "\n",
        "'''\n",
        "* blurring (https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.gaussian)\n",
        "* histogram equalization (https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_equalize.html)\n",
        "* resize images (https://scikit-image.org/docs/stable/auto_examples/transform/plot_rescale.html)\n",
        "'''\n",
        "#Ximages = gaussian(np.float32(Ximages_all.transpose((1,2,0))), sigma=1.0, multichannel=True).transpose(2,0,1)\n",
        "#Ximages = eh(Ximages_all.transpose((1,2,0))).transpose(2,0,1) * 255\n",
        "#height, width = 8, 8; Ximages = resize(np.float32(Ximages_all.transpose((1,2,0))), (height, width)).transpose(2,0,1)\n",
        "\n",
        "''' simulate noisy images '''\n",
        "#Ximages = Ximages_all + np.random.rand(*Ximages_all.shape) * 200; Ximages[Ximages > 255] = 255\n",
        "\n",
        "Ximages = np.uint8(Ximages)\n",
        "print(\"(#images, height, width)\", Ximages.shape)\n",
        "print(Ximages.dtype, \", max. pixel value = \", Ximages.max())\n",
        "\n",
        "c = len(np.unique(y_all))\n",
        "lbl = range(c)\n",
        "y = y_all"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9w91jXrgIKuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST class labels\n",
        "\n",
        "| [MNIST](http://yann.lecun.com/exdb/mnist/) | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |\n",
        "| - | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
        "| [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) | T-shirt/top | Trouser | Pullover | Dress | Coat | Sandal |  Shirt | Sneaker | Bag | Ankle boot |\n",
        "| [Kuzushiji-MNIST](https://github.com/rois-codh/kmnist) | お | き | す | つ | な | は |  ま | や | れ | を |"
      ],
      "metadata": {
        "id": "b85HjGXpQuO3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Ib1PU2n2oK",
        "cellView": "form"
      },
      "source": [
        "#@title 画像を表示する関数 implot を定義し，画像を例示します．\n",
        "!wget -q -N https://gist.githubusercontent.com/tsakai-g/c54a8fa059f9c655290586ec1cc2ec7b/raw/f4d10dc70022dd7c160d4e40940b287863bd5258/implot.py\n",
        "%run implot.py\n",
        "\n",
        "print(\"%d images in total\" % len(y))\n",
        "p = np.random.permutation(len(y))\n",
        "implot(Ximages[p], y[p], num=16, vmin=0, vmax=255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76r4Ic8VAj_g"
      },
      "source": [
        "### 2クラスの識別問題にしたい場合（さもなくば実行しないこと）\n",
        "- このセルの `pos` と `neg` で2クラスを指定します．\n",
        "- 全クラスを使う場合に戻したいときは「☆画像数とサイズを確認します」のセルから実行し直してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVowqB1Z_Pcs"
      },
      "source": [
        "c = 2\n",
        "pos = 1 # choose from 0 to 9\n",
        "neg = 0 # choose from 0 to 9\n",
        "\n",
        "Ximages = Ximages[np.logical_or(y == pos, y == neg)]\n",
        "y = y[np.logical_or(y == pos, y == neg)]\n",
        "yp, yn = y == pos, y== neg\n",
        "y[yp] = 1\n",
        "y[yn] = 0\n",
        "lbl = [neg, pos]\n",
        "\n",
        "p = np.random.permutation(len(y))\n",
        "implot(Ximages[p], y[p], num=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 訓練データと検証データに分けます．\n",
        "- `n_train` と `n_val` で訓練データと検証データの数をそれぞれ指定できます．"
      ],
      "metadata": {
        "id": "H9BCD7UEZxet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = 3000\n",
        "n_val = 1000\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "# split the data into training and validation sets\n",
        "Ximages_train, Ximages_val, y_train, y_val = train_test_split(Ximages, y, \n",
        "                                                              train_size=n_train, test_size=n_val)\n",
        "\n",
        "# reshape to 28*28=784-dimensional feature vectors\n",
        "X_train = np.reshape(Ximages_train, (Ximages_train.shape[0], -1)) / 255   # (n_train, 784)\n",
        "X_val = np.reshape(Ximages_val, (Ximages_val.shape[0], -1)) / 255         # (n_val, 784)\n",
        "print(\"X_train.shape = \", X_train.shape)\n",
        "print(\"X_val.shape = \", X_val.shape)"
      ],
      "metadata": {
        "id": "Zxtu4nWQZvtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ★ロジスティック回帰を実行します．\n",
        "- [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)を使用します．引数の仕様とデフォルトの値を確認してください．\n",
        "- 実装されているロジスティック損失は訓練データ数で除された平均ではありません．[損失の係数`C`](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)で設定できます．"
      ],
      "metadata": {
        "id": "3cy3uyS35LYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 反復数以外はデフォルトの値で実行します．\n",
        "model =  LogisticRegression(max_iter=1000)\n",
        "\n",
        "# 損失の係数`C`を小さい値に設定し，L2正則化の効果を強くします．\n",
        "#model =  LogisticRegression(C=100/n_train, max_iter=1000, penalty='l2')\n",
        "\n",
        "# [Elastic net regularization](https://en.wikipedia.org/wiki/Elastic_net_regularization) i.e., L1+L2 regularization\n",
        "#model =  LogisticRegression(C=100/n_train, penalty='elasticnet', l1_ratio=0.5, solver='saga')\n",
        "\n",
        "# sparse regularization\n",
        "#model =  LogisticRegression(penalty='l1', solver='saga')\n",
        "\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "A9x3n9YUwW7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 識別の結果を例示します（上：訓練データ，下：検証データ）．\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(X_train)\n",
        "print(\"Accuracy on training data: \", accuracy_score(y_train, y_pred))\n",
        "p = np.random.permutation(n_train)\n",
        "implot(Ximages_train[p], y_train[p], y_pred[p], num=16)\n",
        "plt.show()\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "print(\"\\nAccuracy on validation data: \", accuracy_score(y_val, y_pred))\n",
        "p = np.random.permutation(n_val)\n",
        "implot(Ximages_val[p], y_val[p], y_pred[p], num=16)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Hp6UlrFybtks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST class labels\n",
        "\n",
        "| [MNIST](http://yann.lecun.com/exdb/mnist/) | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |\n",
        "| - | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
        "| [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) | T-shirt/top | Trouser | Pullover | Dress | Coat | Sandal |  Shirt | Sneaker | Bag | Ankle boot |\n",
        "| [Kuzushiji-MNIST](https://github.com/rois-codh/kmnist) | お | き | す | つ | な | は |  ま | や | れ | を |"
      ],
      "metadata": {
        "id": "-90fcIXUSjBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ★学習した重みを可視化し，識別関数を計算します．\n",
        "\n",
        "w = np.c_[model.intercept_, model.coef_]\n",
        "#print(w.shape)\n",
        "\n",
        "# Plot the weights\n",
        "fig = plt.figure(figsize=(12, 3))  # figure size in inches\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "cmap = plt.cm.seismic\n",
        "\n",
        "from matplotlib.colors import TwoSlopeNorm as tsn\n",
        "#import warnings\n",
        "#warnings.filterwarnings(\"ignore\")#, category=np.VisibleDeprecationWarning)\n",
        "\n",
        "jval = np.random.randint(n_val,size=1) # draw one test sample\n",
        "vmin = w[:,1:].min()\n",
        "vmax = -vmin\n",
        "xmax=max(X_val[jval,:].ravel())\n",
        "\n",
        "if c == 2:\n",
        "    c = 1\n",
        "for k in range(c):\n",
        "  \n",
        "    ax = fig.add_subplot(3, c, k + 1, xticks=[], yticks=[])\n",
        "    norm = tsn(vmin=np.minimum(w[k,1:].min(),-1e-6), vcenter=0, vmax=np.maximum(w[k,1:].max(),1e-6))\n",
        "    ax.imshow(w[k,1:].reshape(Ximages.shape[1], Ximages.shape[2]), cmap=cmap, norm=norm)\n",
        "    if c == 1:\n",
        "        ax.text(0, 4, str(lbl[c]) + ' ?', color='k')\n",
        "    else:\n",
        "        ax.text(0, 4, str(lbl[k]) + ' ?', color='k')\n",
        "\n",
        "    ax = fig.add_subplot(3, c, k + c + 1, xticks=[], yticks=[])\n",
        "    #ax.imshow(X_val[jval,:].reshape(Ximages.shape[1], Ximages.shape[2]), cmap=plt.cm.gray)\n",
        "    ax.imshow(Ximages_val[jval].squeeze(), cmap=plt.cm.gray)\n",
        "    ax.text(0, 7, str(lbl[y_val[jval][0]]), color='white')\n",
        "\n",
        "    wXk = X_val[jval,:].ravel()*w[k,1:]\n",
        "    ax = fig.add_subplot(3, c, k + 2*c + 1, xticks=[], yticks=[])\n",
        "    norm = tsn(vmin=np.minimum(wXk.min(),-1e-6)*xmax, vcenter=0, vmax=np.maximum(wXk.max(),1e-6)*xmax)\n",
        "    ax.imshow(wXk.reshape(Ximages.shape[1], Ximages.shape[2]), cmap=cmap, norm=norm)\n",
        "    g = wXk.sum()+w[k,0]\n",
        "    if g >= 0:\n",
        "        color='r'\n",
        "    else:\n",
        "        color='b'\n",
        "    ax.text(0, 4, str(lbl[model.predict(X_val)[jval][0]]), color=color)\n",
        "    ax.text(0, 33, '$g=$'+'{:.1f}'.format(g), fontsize=max(10+g,10), color=color)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6mx_xM-dTp6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "可視化の説明：\n",
        "- <b>上段</b>：パーセプトロンの入力の画素値に対応する重みを図示しています．\n",
        "    - 赤が正，青は負 の重みを表します．\n",
        "    - 2クラスの場合は，正と負がそれぞれ`pos`と`neg`に寄与する重みです．\n",
        "- <b>中段</b>：入力画像です．画素値は非負で，黒はゼロです．\n",
        "- <b>下段</b>：パーセプトロンの重み（上段）と入力画像（中段）の画素値の積を図示しています．\n",
        "- 各クラスのパーセプトロンが計算した識別関数 <i>g</i> を各列の下に表示しています．"
      ],
      "metadata": {
        "id": "rv14A4EyrqDk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is9z76Bdn2oe",
        "cellView": "form"
      },
      "source": [
        "#@title 混同行列（行：正解，列：予測）\n",
        "from sklearn import metrics\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "\n",
        "cm = metrics.confusion_matrix(y_val, y_pred)\n",
        "print(cm)\n",
        "\n",
        "print(cm.sum(axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRUeztQpn2op",
        "cellView": "form"
      },
      "source": [
        "#@title おまけ\n",
        "import seaborn as sns\n",
        "\n",
        "# Make predictions on test data\n",
        "cm = metrics.confusion_matrix(y_val, y_pred)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "## 発展課題（任意）\n",
        "\n",
        "[MedMNIST](https://github.com/MedMNIST/MedMNIST)を使ってましょう．\n",
        "手書き数字画像のように手軽に使える実験用の医用画像です．  \n",
        "下の2つのセルを実行後は，このJupyter Notebook前半の  \n",
        "「☆画像数とサイズを確認します（画像を加工したい場合はこのセルを編集して利用してください）．」  \n",
        "以降を実行できます．\n",
        "\n",
        "    1. PneumoniaMNISTは胸部X線CT画像です．'0': 正常, '1': 異常（肺炎）の2クラス識別問題です．\n",
        "       学習したパーセプトロンは，主に画像のどこの画素値をどのように重みづけしますか．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    2. MedMNISTにはどのような医用画像の識別問題がありますか．\n",
        "\n",
        "（ここに回答を書いてください）[参考文献](https://arxiv.org/abs/2110.14795)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2QsruOf_mYxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [MedMNIST](https://github.com/MedMNIST/MedMNIST)を取得します．\n",
        "!pip install -q medmnist\n",
        "import medmnist\n",
        "print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "19n5ZTkG1eH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'pneumoniamnist', 'chestmnist', 'octmnist', 'breastmnist', 'tissuemnist', 'organamnist', 'organcmnist', 'organsmnist' \n",
        "data_flag = 'pneumoniamnist' \n",
        "DataClass = getattr(medmnist, medmnist.INFO[data_flag]['python_class'])\n",
        "\n",
        "tvds = DataClass(split='train', download=True)\n",
        "#tvds = DataClass(split='test', download=True)\n",
        "\n",
        "print(tvds)\n",
        "Ximages_all, y_all = tvds.imgs, tvds.labels.ravel()"
      ],
      "metadata": {
        "id": "2JWf5Htq1eLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "お疲れさまでした．"
      ],
      "metadata": {
        "id": "jBz0cgBO0qZM"
      }
    }
  ]
}