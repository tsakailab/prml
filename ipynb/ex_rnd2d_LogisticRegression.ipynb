{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/prml/blob/master/ipynb/ex_rnd2d_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UTNIg2oEn2n8"
      },
      "cell_type": "markdown",
      "source": [
        "# 2次元データのロジスティック回帰（logistic regression of a 2D dataset）\n",
        "\n",
        "----\n",
        "\n",
        "氏名：\n",
        "\n",
        "学生番号：\n",
        "\n",
        "----\n",
        "基本課題（必須）\n",
        "\n",
        "    1. 「★scikit-learnを用いたロジスティック回帰」まで実行すると，どのような数値と図が出力されますか．\n",
        "       また，表示される数値と図から何が言えますか．特に，Example 2とExample 3について記述してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    2. 「★scikit-learnを用いたロジスティック回帰」で使用している model.fit(X, y) と\n",
        "        model.decision_function(X) はそれぞれ何をする関数ですか．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    3. 最急降下法によるロジスティック回帰を実装してください．\n",
        "\n",
        "（回答はこのファイルの後半「★最急降下法によるロジスティック回帰の実装」に書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    4.その他，気づいたこと，調べたことを書いてください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "発展課題（任意）がこのノートブックの後半にあります．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2次元に2クラスを描く `plot2cls` を定義します（理解不要）．\n",
        "!wget -q -N https://gist.githubusercontent.com/tsakai-g/1920bc185be0c497579968e00a9b3674/raw/plot2cls.py\n",
        "%run plot2cls.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kkKF2Idqdx_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 実験用のデータ（2次元，2クラス）を生成します．\n",
        "- Example 1～4 からひとつ選んで実行してください．"
      ],
      "metadata": {
        "id": "4byvUzevPKta"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQWiGCU0G9aA"
      },
      "source": [
        "# Example 1: y = or(x1, x2)\n",
        "X = np.array([[0, 0], [1,0], [0,1], [1,1]])\n",
        "y = np.array([-1,1,1,1])\n",
        "\n",
        "X_val = X + np.random.randn(4, 2) * 0.2\n",
        "y_val = y.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPcFoZwoU2fp"
      },
      "source": [
        "# Example 2: draw npos and nneg points from the Gaussian distribution for each class\n",
        "npos = 30\n",
        "nneg = 30\n",
        "np.random.seed(321)\n",
        "X = np.r_[np.random.randn(npos, 2) + [3, 3], np.random.randn(nneg, 2)]\n",
        "# [1,1,...,1,-1,-1,...,-1]\n",
        "y = np.array([1] * npos + [-1] * nneg)\n",
        "\n",
        "X_val = X + np.random.randn(X.shape[0], 2) * 1.0\n",
        "y_val = y.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAcLs8fxU3b8"
      },
      "source": [
        "# Example 3: create moons using sklearn\n",
        "from sklearn.datasets import make_moons\n",
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=0)\n",
        "y[y==0] = -1\n",
        "\n",
        "X_val, y_val = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "y_val[y_val==0] = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5xj700RhOad"
      },
      "source": [
        "# Example 4: create circles using sklearn\n",
        "from sklearn.datasets import make_circles\n",
        "X, y = make_circles(n_samples=150, noise=0.1, random_state=0, factor=0.3)\n",
        "y[y==0] = -1\n",
        "\n",
        "X_val, y_val = make_circles(n_samples=150, noise=0.1, random_state=1, factor=0.3)\n",
        "y_val[y_val==0] = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title データを表示します．\n",
        "plot2cls(X, y, X_val=X_val, y_val=y_val).plot_data()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dCj3rKLVdyQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ★scikit-learn を用いたロジスティック回帰\n",
        "\n",
        "[sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)を使用した結果を出力します．"
      ],
      "metadata": {
        "id": "ssqJLogmRkli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()  #(penalty='none')\n",
        "model.fit(X, y)\n",
        "\n",
        "# print([w0], [w1, w2])\n",
        "print(\"w0 =\", model.intercept_, \",  w =\", model.coef_.ravel())\n",
        "\n",
        "print(\"Accuracy on training data: \", model.score(X, y))\n",
        "print(\"Accuracy on validation data: \", model.score(X_val, y_val))\n",
        "\n",
        "dec = lambda X: model.decision_function(X)\n",
        "plot2cls(X, y, dec, X_val, y_val).plot_clf()"
      ],
      "metadata": {
        "id": "_PE0o7dTdyS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 最急降下法によるロジスティック回帰の学習アルゴリズム\n",
        "参考資料 [■](https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html) [■](https://math.stackexchange.com/questions/78575/derivative-of-sigmoid-function-sigma-x-frac11e-x)\n",
        "\n",
        "適当な初期値から，学習率 $\\alpha>0$ で $w_0$ と $\\boldsymbol w$ の修正を次式のように反復します．\n",
        "\n",
        "$\\qquad w_0\\gets w_0 - \\alpha{\\mathit\\Delta}w_0$  \n",
        "$\\qquad \\boldsymbol w\\gets \\boldsymbol w - \\alpha{\\mathit\\Delta}\\boldsymbol w$\n",
        "\n",
        "修正量 ${\\mathit\\Delta}w_0$ と ${\\mathit\\Delta}\\boldsymbol w$ は平均ロジスティック損失 $L(w_0,\\boldsymbol w)$ の勾配で，次式のように表せます．\n",
        "\n",
        "${\\mathit\\Delta}w_0=\\;\\;\\;\\frac{\\partial L(w_0,\\boldsymbol w)}{\\partial w_0}\\;\\; = \\frac{1}{n}\\sum_{j=1}^n \\varepsilon^{(j)}$  \n",
        "\n",
        "${\\mathit\\Delta}\\boldsymbol w=\\left[\\matrix{\\frac{\\partial L(w_0,\\boldsymbol w)}{\\partial w_1}\\\\ \\vdots \\\\\\frac{\\partial L(w_0,\\boldsymbol w)}{\\partial w_d}}\\right] = \\frac{1}{n}\\sum_{j=1}^n \\varepsilon^{(j)}\\boldsymbol x^{(j)}$  \n",
        "\n",
        "ただし，\n",
        "$\\varepsilon^{(j)}=\\left\\{\\begin{array}{cl}p^{(j)}-1 & (y^{(j)}=+1)\\\\ p^{(j)} & (y^{(j)}=-1)\\end{array}\\right.\\qquad$  （確率 $p^{(j)}$ を正解 $y^{(j)}$ と比較した誤差）  \n",
        "\n",
        "$[p^{(1)},\\dots,p^{(n)}]=[\\mathrm{sigmoid}(g(\\boldsymbol x^{(1)})),\\dots,\\mathrm{sigmoid}(g(\\boldsymbol x^{(n)}))]$  \n",
        "\n",
        "です．つまり，データ $\\boldsymbol x^{(j)}$ に対する識別関数の出力を確率 $p^{(j)}$ に換算し，\n",
        "- 正解が $y^{(j)}=+1$ ならば $p^{(j)}$ が $1$ に近いほどよい（$\\varepsilon^{(j)}=p^{(j)}-1$）\n",
        "- 正解が $y^{(j)}=-1$ ならば $p^{(j)}$ が $0$ に近いほどよい（$\\varepsilon^{(j)}=p^{(j)}$）\n",
        "\n",
        "として誤差 $\\varepsilon^{(j)}$ が計算されています．誤差が大きいほど修正量に加味されます．"
      ],
      "metadata": {
        "id": "XhFha4t1wYhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ★最急降下法によるロジスティック回帰の実装\n",
        "\n",
        "LogisticRegressionGDという名のクラスとして実装しましょう．[sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) に似た仕様とします．\n",
        "\n",
        "訓練データ `X_train` とクラスラベル `y_train` を学習したあと，`X_val` のクラスラベルの予測 `y_pred` を得たり，正答率を表示するには，\n",
        "```\n",
        "    myclf = LogisticRegressionGD(lr=1e-2, max_iter=300)\n",
        "    myclf.fit(X_train, y_train)\n",
        "    y_pred = myclf.predict(X_val)\n",
        "    print(myclf.score(X_val, y_val))\n",
        "```\n",
        "のように使うことを想定します．ここで，`lr` は学習率（learning rate），`max_iter` は反復回数（maximum number of iterations）です．\n",
        "訓練データの次元数`d`，個数`n`の場合，`X_train` と `y_train` はそれぞれ shape が `(n,d)` と `(n,)` のNumPy配列です．ただし，`y_train` は2クラスを +1と-1で表すものとします．"
      ],
      "metadata": {
        "id": "UBYXMS7ICxHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LogisticRegressionGD:\n",
        "\n",
        "    def __init__(self, lr=1., max_iter=1000):\n",
        "        self.lr = lr\n",
        "        self.max_iter = max_iter\n",
        "        self.intercept_ = None                          # w0\n",
        "        self.coef_ = None                               # [w1,...,wd}\n",
        "        self.loss_history = []                          # 損失の履歴\n",
        "\n",
        "\n",
        "    # 識別関数 g(x) = w0 + w1*x1 + ... + wd*xd\n",
        "    def decision_function(self, X):                     # X(n,d)\n",
        "        return ''' self.intercept_ と X.dot(self.coef_) を使う '''\n",
        "\n",
        "    # シグモイド関数 sigmoid(z) = 1/ (1 + exp(-z))\n",
        "    def _sigmoid(self, z):                              # z(n,)\n",
        "        return ''' np.exp() を使う '''\n",
        "\n",
        "    # 平均ロジスティック損失 (1/n)Σ log(1 + exp(-y*g(x)) )\n",
        "    def ave_loss(self, X, y):                           # X(n,d), y(n,)\n",
        "        loss = ''' self.decision_function(), np.log(), len(y) を使う '''\n",
        "        return loss\n",
        "\n",
        "\n",
        "    # 学習：最急降下法で w0,...,wdを最適化します\n",
        "    def fit(self, X, y):                                # X(n,d), y(n,)\n",
        "        n, d = X.shape\n",
        "\n",
        "        # w0 と [w1,...,wd] の初期化\n",
        "        if self.intercept_ is None: self.intercept_ = 0\n",
        "        if self.coef_ is None: self.coef_ = np.zeros(d)\n",
        "\n",
        "        # 勾配による修正の反復\n",
        "        for _ in range(self.max_iter):\n",
        "            p = ''' self.decision_function() と self._sigmoid() を使う．'''\n",
        "            e = np.where(y > 0, p - 1, p)               # e(n,)\n",
        "\n",
        "            dw0 = e.sum() / n\n",
        "            dw = e.dot(X) / n\n",
        "\n",
        "            self.intercept_ -= ''' self.lr と dw0 を使う '''\n",
        "            self.coef_ -= ''' self.lr と dw を使う '''\n",
        "\n",
        "            self.loss_history.append( self.ave_loss(X, y) )\n",
        "\n",
        "\n",
        "    # 推論\n",
        "    def predict(self, X):                               # X(n,d)\n",
        "        y_pred = self.decision_function(X)              # y_pred(n,)\n",
        "        return np.where(y_pred > 0, 1, -1)              # (n,)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        return (y == y_pred).sum() / len(y)"
      ],
      "metadata": {
        "id": "0wgc_5GpGjyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 実装した`LogisticRegressionGD`で識別します．"
      ],
      "metadata": {
        "id": "5Bk1HovpADsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegressionGD()  # lr=100.\n",
        "model.fit(X, y)\n",
        "\n",
        "# print([w0], [w1, w2])\n",
        "print(\"w0 =\", model.intercept_, \",  w =\", model.coef_.ravel())\n",
        "\n",
        "print(\"Accuracy on training data: \", model.score(X, y))\n",
        "print(\"Accuracy on validation data: \", model.score(X_val, y_val))\n",
        "\n",
        "plt.plot(model.loss_history)\n",
        "\n",
        "dec = lambda X: model.decision_function(X)\n",
        "plot2cls(X, y, dec, X_val, y_val).plot_clf()"
      ],
      "metadata": {
        "id": "C95O9uF8MmE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "## 発展課題（任意）\n",
        "\n",
        "学習率や反復回数を大きくした場合を考えましょう．  \n",
        "最急降下法によるロジスティック回帰では，同じ問題設定でも scikit-learn の場合と決定境界が異なっていることを確認してください．特に，学習率や反復回数を大きくするほど，求まる重み（`w0` や `[w1,...,wd]`）の値が大きくなります．\n",
        "\n",
        "    1. 重みの大きさと，平均ロジスティック損失の関係を説明してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "ヒント：平均ロジスティック損失 $L(w_0,\\boldsymbol w)=\\frac{1}{n}\\sum_{j=1}^n\\log\\left(1+e^{-y^{(j)}(w_0+\\boldsymbol w^\\top\\boldsymbol x^{(j)})}\\right)$\n",
        "\n",
        "    2. 「★最急降下法によるロジスティック回帰の実装」を変更してL2正則化を導入し，\n",
        "       scikit-learn と同じ結果を再現してください．\n",
        "\n",
        "（コードに変更を施した行の変更前後をここに書いてください）\n",
        "\n",
        "\n",
        "ヒント：\n",
        "- L2正則化項を付加した最小化問題： $\\mathrm{Minimize}_{(w_0,\\boldsymbol w)}\\quad L(w_0,\\boldsymbol w)+\\frac{1}{2}\\|\\boldsymbol w\\|_2^2\\qquad$  （ただし，$\\|\\boldsymbol w\\|_2^2=w_1^2+\\cdots+w_d^2$）\n",
        "- L2正則化項 $\\frac{1}{2}\\|\\boldsymbol w\\|_2^2$ の勾配は $\\boldsymbol w$ なので， $\\boldsymbol w$ の修正量 $\\mathit\\Delta\\boldsymbol w$ が $\\boldsymbol w$ だけ増える．\n",
        "- fit を一行変更するだけで済む．$\\boldsymbol w$ は `self.coef_` のこと．\n",
        "- [scikit-learn の最小化問題は `n` で除さない仕様なので](https://scikit-learn.org/stable/modules/linear_model.html#binary-case)，平均ロジスティック損失を採用している場合は `self.coef_ / n` だけ修正量を増やす．\n",
        "\n",
        "\n",
        "    3. L2正則化を導入したアルゴリズムでは，学習率を大きくすると，重みは大きくならないが，収束しなくなる．  \n",
        "       このことを確認し，収束しない理由を説明してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n"
      ],
      "metadata": {
        "id": "jVhtoi5sM0Wm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "お疲れさまでした．"
      ],
      "metadata": {
        "id": "-svKKyHE-Vcl"
      }
    }
  ]
}